{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.analysis.plotting import plot_spikes, plot_voltages\n",
    "\n",
    "# Simulation time.\n",
    "time = 500\n",
    "\n",
    "# Create the network.\n",
    "network = Network()\n",
    "\n",
    "# Create and add input, output layers.\n",
    "source_layer = Input(n=30)\n",
    "target_layer = LIFNodes(n=10)\n",
    "\n",
    "network.add_layer(\n",
    "    layer=source_layer, name=\"A\"\n",
    ")\n",
    "network.add_layer(\n",
    "    layer=target_layer, name=\"B\"\n",
    ")\n",
    "\n",
    "# Create connection between input and output layers.\n",
    "forward_connection = Connection(\n",
    "    source=source_layer,\n",
    "    target=target_layer,\n",
    "    w=0.05 + 0.1 * torch.randn(source_layer.n, target_layer.n),  # Normal(0.05, 0.01) weights.\n",
    ")\n",
    "\n",
    "network.add_connection(\n",
    "    connection=forward_connection, source=\"A\", target=\"B\"\n",
    ")\n",
    "\n",
    "# Create recurrent connection in output layer.\n",
    "recurrent_connection = Connection(\n",
    "    source=target_layer,\n",
    "    target=target_layer,\n",
    "    w=0.025 * (torch.eye(target_layer.n) - 1), # Small, inhibitory \"competitive\" weights.\n",
    ")\n",
    "\n",
    "network.add_connection(\n",
    "    connection=recurrent_connection, source=\"B\", target=\"B\"\n",
    ")\n",
    "\n",
    "# Create and add input and output layer monitors.\n",
    "source_monitor = Monitor(\n",
    "    obj=source_layer,\n",
    "    state_vars=(\"s\",),  # Record spikes and voltages.\n",
    "    time=time,  # Length of simulation (if known ahead of time).\n",
    ")\n",
    "target_monitor = Monitor(\n",
    "    obj=target_layer,\n",
    "    state_vars=(\"s\", \"v\"),  # Record spikes and voltages.\n",
    "    time=time,  # Length of simulation (if known ahead of time).\n",
    ")\n",
    "\n",
    "network.add_monitor(monitor=source_monitor, name=\"A\")\n",
    "network.add_monitor(monitor=target_monitor, name=\"B\")\n",
    "\n",
    "# Create input spike data, where each spike is distributed according to Bernoulli(0.1).\n",
    "input_data = torch.bernoulli(0.1 * torch.ones(time, source_layer.n)).byte()\n",
    "# dataset = load_breast_cancer()\n",
    "# input_data = dataset.data\n",
    "inputs = {\"A\": input_data}\n",
    "\n",
    "# Simulate network on input data.\n",
    "network.run(inputs=inputs, time=time)\n",
    "\n",
    "# Retrieve and plot simulation spike, voltage data from monitors.\n",
    "spikes = {\n",
    "    \"A\": source_monitor.get(\"s\"), \"B\": target_monitor.get(\"s\")\n",
    "}\n",
    "voltages = {\"B\": target_monitor.get(\"v\")}\n",
    "\n",
    "plt.ioff()\n",
    "plot_spikes(spikes)\n",
    "plot_voltages(voltages, plot_type=\"line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations # 0\n",
      "Iterations # 1000\n",
      "Iterations # 2000\n",
      "Iterations # 3000\n",
      "Iterations # 4000\n",
      "Iterations # 5000\n",
      "Iterations # 6000\n",
      "Iterations # 7000\n",
      "Iterations # 8000\n",
      "Iterations # 9000\n",
      "Iterations # 10000\n",
      "Iterations # 11000\n",
      "Iterations # 12000\n",
      "Iterations # 13000\n",
      "Iterations # 14000\n",
      "Iterations # 15000\n",
      "Iterations # 16000\n",
      "Iterations # 17000\n",
      "Iterations # 18000\n",
      "Iterations # 19000\n",
      "Iterations # 20000\n",
      "Iterations # 21000\n",
      "Iterations # 22000\n",
      "Iterations # 23000\n",
      "Iterations # 24000\n",
      "Iterations # 25000\n",
      "Iterations # 26000\n",
      "Iterations # 27000\n",
      "Iterations # 28000\n",
      "Iterations # 29000\n",
      "Iterations # 30000\n",
      "Iterations # 31000\n",
      "Iterations # 32000\n",
      "Iterations # 33000\n",
      "Iterations # 34000\n",
      "Iterations # 35000\n",
      "Iterations # 36000\n",
      "Iterations # 37000\n",
      "Iterations # 38000\n",
      "Iterations # 39000\n",
      "Iterations # 40000\n",
      "Iterations # 41000\n",
      "Iterations # 42000\n",
      "Iterations # 43000\n",
      "Iterations # 44000\n",
      "Iterations # 45000\n",
      "Iterations # 46000\n",
      "Iterations # 47000\n",
      "Iterations # 48000\n",
      "Iterations # 49000\n",
      "Iterations # 50000\n",
      "Iterations # 51000\n",
      "Iterations # 52000\n",
      "Iterations # 53000\n",
      "Iterations # 54000\n",
      "Iterations # 55000\n",
      "Iterations # 56000\n",
      "Iterations # 57000\n",
      "Iterations # 58000\n",
      "Iterations # 59000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.datasets import FashionMNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.network.nodes import Input, IFNodes\n",
    "\n",
    "# Network building\n",
    "network = Network()\n",
    "\n",
    "input_layer = Input(n=784, sum_input=True)\n",
    "output_layer = IFNodes(n=10, sum_input=True)\n",
    "network.add_layer(input_layer, name='X')\n",
    "network.add_layer(output_layer, name= 'Y')\n",
    "\n",
    "input_connection = Connection(input_layer, output_layer, norm=150, wmin=-1, wmax=1)\n",
    "network.add_connection(input_connection, source='X', target='Y')\n",
    "\n",
    "# State Variable Monitoring\n",
    "time = 25\n",
    "for l in network.layers:\n",
    "    m = Monitor(network.layers[l], state_vars = ['s'], time=time)\n",
    "    network.add_monitor(m, name=l)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=time)\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)\n",
    "\n",
    "# Load Data\n",
    "dataset = FashionMNIST(\n",
    "    None,\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    ")\n",
    "images = dataset.data\n",
    "labels = dataset.targets\n",
    "\n",
    "# Run Training\n",
    "grads = {}\n",
    "lr, lr_decay = 1e-2, 0.95\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "spike_ims, spike_axes, weights_im = None, None, None\n",
    "for i, (image, label) in enumerate(zip(images.view(-1, 784), labels)):\n",
    "    if(i%1000 == 0):\n",
    "        print(\"Iterations # {}\".format(i))\n",
    "\n",
    "    # Run simulation for single datum\n",
    "    inputs = {'X': image.repeat(time, 1), 'Y_b': torch.ones(time, 1)}\n",
    "    network.run(inputs = inputs, time=time)\n",
    "\n",
    "    # Retrieve spikes and summed inputs from both layers\n",
    "    label = torch.tensor(label).long()\n",
    "    spikes = {l: network.monitors[l].get('s') for l in network.layers}\n",
    "    summed_inputs = {l: network.layers[l].summed for l in network.layers}\n",
    "\n",
    "    # Compute softmax of output activity\n",
    "    output = spikes['Y'].sum(-1).type(torch.float).softmax(0).view(1, -1)\n",
    "    predicted = output.argmax(1).item()\n",
    "\n",
    "    # Compute gradient of loss and do SGD update\n",
    "    grads['dl/df'] = summed_inputs['Y'].softmax(0)\n",
    "    grads['dl/df'][0][label] -= 1\n",
    "    grads['dl/dw'] = torch.ger(summed_inputs['X'][0], grads['dl/df'][0])\n",
    "    network.connections['X', 'Y'].w -= lr*grads['dl/dw']\n",
    "\n",
    "    #Decay learning rate\n",
    "    if i > 0 and i%500 == 0:\n",
    "        lr *= lr_decay \n",
    "\n",
    "    network.reset_state_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Monitor' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a22c63f30ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_spikes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_voltages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoltages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/bindsnet/analysis/plotting.py\u001b[0m in \u001b[0;36mplot_voltages\u001b[0;34m(voltages, ims, axes, time, n_neurons, cmap, plot_type, thresholds, figsize)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;31m# for key in voltages.keys():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;31m#     voltages[key] = voltages[key].view(-1, voltages[key].size(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mvoltages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvoltages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/bindsnet/analysis/plotting.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;31m# for key in voltages.keys():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;31m#     voltages[key] = voltages[key].view(-1, voltages[key].size(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mvoltages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvoltages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Monitor' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "from bindsnet.analysis.plotting import plot_spikes, plot_voltages\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.ioff()\n",
    "plot_spikes(spikes)\n",
    "plot_voltages(voltages, plot_type=\"line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = spikes['Y'].sum(-1).type(torch.float).softmax(0).view(1, -1)\n",
    "predicted_ = output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED] [--n_neurons N_NEURONS]\n",
      "                             [--n_train N_TRAIN] [--n_test N_TEST]\n",
      "                             [--n_clamp N_CLAMP] [--exc EXC] [--inh INH]\n",
      "                             [--theta_plus THETA_PLUS] [--time TIME] [--dt DT]\n",
      "                             [--intensity INTENSITY]\n",
      "                             [--progress_interval PROGRESS_INTERVAL]\n",
      "                             [--update_interval UPDATE_INTERVAL] [--train]\n",
      "                             [--test] [--plot] [--gpu] [--device_id DEVICE_ID]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/bhargavjoshi/Library/Jupyter/runtime/kernel-083246d1-0931-4bba-95da-e7361792b263.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_assignments,\n",
    "    plot_performance,\n",
    "    plot_weights,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    ")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "parser.add_argument(\"--n_neurons\", type=int, default=100)\n",
    "parser.add_argument(\"--n_train\", type=int, default=5000)\n",
    "parser.add_argument(\"--n_test\", type=int, default=1000)\n",
    "parser.add_argument(\"--n_clamp\", type=int, default=1)\n",
    "parser.add_argument(\"--exc\", type=float, default=22.5)\n",
    "parser.add_argument(\"--inh\", type=float, default=120)\n",
    "parser.add_argument(\"--theta_plus\", type=float, default=0.05)\n",
    "parser.add_argument(\"--time\", type=int, default=250)\n",
    "parser.add_argument(\"--dt\", type=int, default=1.0)\n",
    "parser.add_argument(\"--intensity\", type=float, default=32)\n",
    "parser.add_argument(\"--progress_interval\", type=int, default=10)\n",
    "parser.add_argument(\"--update_interval\", type=int, default=250)\n",
    "parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
    "parser.add_argument(\"--test\", dest=\"train\", action=\"store_false\")\n",
    "parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\n",
    "parser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0)\n",
    "parser.set_defaults(plot=False, gpu=False, train=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "seed = args.seed\n",
    "n_neurons = args.n_neurons\n",
    "n_train = args.n_train\n",
    "n_test = args.n_test\n",
    "n_clamp = args.n_clamp\n",
    "exc = args.exc\n",
    "inh = args.inh\n",
    "theta_plus = args.theta_plus\n",
    "time = args.time\n",
    "dt = args.dt\n",
    "intensity = args.intensity\n",
    "progress_interval = args.progress_interval\n",
    "update_interval = args.update_interval\n",
    "train = args.train\n",
    "plot = args.plot\n",
    "gpu = args.gpu\n",
    "device_id = args.device_id\n",
    "\n",
    "# Sets up Gpu use\n",
    "if gpu and torch.cuda.is_available():\n",
    "    # torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    torch.cuda.set_device(device_id)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "per_class = int(n_neurons / 10)\n",
    "\n",
    "# Build Diehl & Cook 2015 network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    nu=[1e-2, 1e-4],\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=time)\n",
    "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=time)\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "\n",
    "# Load MNIST data.\n",
    "dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create a dataloader to iterate and batch data\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(update_interval, time, n_neurons)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "assignments = -torch.ones_like(torch.Tensor(n_neurons))\n",
    "proportions = torch.zeros_like(torch.Tensor(n_neurons, 10))\n",
    "rates = torch.zeros_like(torch.Tensor(n_neurons, 10))\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Labels to determine neuron assignments and spike proportions and estimate accuracy\n",
    "labels = torch.empty(update_interval)\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "# Train the network.\n",
    "print(\"Begin training.\\n\")\n",
    "\n",
    "inpt_axes = None\n",
    "inpt_ims = None\n",
    "spike_axes = None\n",
    "spike_ims = None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes = None\n",
    "voltage_ims = None\n",
    "\n",
    "pbar = tqdm(total=n_train)\n",
    "for (i, datum) in enumerate(dataloader):\n",
    "    if i > n_train:\n",
    "        break\n",
    "\n",
    "    image = datum[\"encoded_image\"]\n",
    "    label = datum[\"label\"]\n",
    "\n",
    "    if i % update_interval == 0 and i > 0:\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(spike_record, assignments, 10)\n",
    "        proportion_pred = proportion_weighting(\n",
    "            spike_record, assignments, proportions, 10\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100 * torch.sum(labels.long() == all_activity_pred).item() / update_interval\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100 * torch.sum(labels.long() == proportion_pred).item() / update_interval\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "            % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"]))\n",
    "        )\n",
    "        print(\n",
    "            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"\n",
    "            % (\n",
    "                accuracy[\"proportion\"][-1],\n",
    "                np.mean(accuracy[\"proportion\"]),\n",
    "                np.max(accuracy[\"proportion\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(spike_record, labels, 10, rates)\n",
    "\n",
    "    # Add the current label to the list of labels for this update_interval\n",
    "    labels[i % update_interval] = label[0]\n",
    "\n",
    "    # Run the network on the input.\n",
    "    choice = np.random.choice(int(n_neurons / 10), size=n_clamp, replace=False)\n",
    "    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "    if gpu:\n",
    "        inputs = {\"X\": image.cuda().view(time, 1, 1, 28, 28)}\n",
    "    else:\n",
    "        inputs = {\"X\": image.view(time, 1, 1, 28, 28)}\n",
    "    network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "\n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n",
    "\n",
    "    # Optionally plot various simulation information.\n",
    "    if plot:\n",
    "        inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n",
    "        input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n",
    "        square_weights = get_square_weights(\n",
    "            input_exc_weights.view(784, n_neurons), n_sqrt, 28\n",
    "        )\n",
    "        square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "        voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "\n",
    "        inpt_axes, inpt_ims = plot_input(\n",
    "            image.sum(1).view(28, 28), inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "        )\n",
    "        spike_ims, spike_axes = plot_spikes(\n",
    "            {layer: spikes[layer].get(\"s\").view(time, 1, -1) for layer in spikes},\n",
    "            ims=spike_ims,\n",
    "            axes=spike_axes,\n",
    "        )\n",
    "        weights_im = plot_weights(square_weights, im=weights_im)\n",
    "        assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "        perf_ax = plot_performance(accuracy, ax=perf_ax)\n",
    "        voltage_ims, voltage_axes = plot_voltages(\n",
    "            voltages, ims=voltage_ims, axes=voltage_axes\n",
    "        )\n",
    "\n",
    "        plt.pause(1e-8)\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Train progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(\"Progress: %d / %d \\n\" % (n_train, n_train))\n",
    "print(\"Training complete.\\n\")\n",
    "\n",
    "\n",
    "print(\"Testing....\\n\")\n",
    "\n",
    "hit = 0\n",
    "pbar = tqdm(total=n_test)\n",
    "for (i, datum) in enumerate(dataloader):\n",
    "    if i > n_test:\n",
    "        break\n",
    "\n",
    "    image = datum[\"encoded_image\"]\n",
    "    label = datum[\"label\"]\n",
    "    if gpu:\n",
    "        inputs = {\"X\": image.cuda().view(time, 1, 1, 28, 28)}\n",
    "    else:\n",
    "        inputs = {\"X\": image.view(time, 1, 1, 28, 28)}\n",
    "\n",
    "    network.run(inputs=inputs, time=time)\n",
    "\n",
    "    out_spikes = network.monitors[\"Ae_spikes\"].get(\"s\")\n",
    "\n",
    "    out_spikes = out_spikes.squeeze().sum(dim=0)\n",
    "    class_spike = torch.zeros(10)\n",
    "    for c in range(10):\n",
    "        class_spike[c] = out_spikes[i * 10 : (c + 1) * 10].sum()\n",
    "    maxInd = class_spike.argmax()\n",
    "    if maxInd == label[0]:\n",
    "        hit += 1\n",
    "\n",
    "    pbar.set_description_str(f\"Accuracy: {hit / (i+1)}\")\n",
    "    pbar.update()\n",
    "\n",
    "acc = hit / n_test\n",
    "print(\"\\n accuracy: \" + str(acc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('py37': conda)",
   "language": "python",
   "name": "python37764bitpy37conda34757eb3777e4ef18aaea4b8199c344c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
